##А

**Точность (Accuracy)**: мера того, насколько хорошо модель классифицирует примеры. Рассчитывается как доля правильно классифицированных примеров от общего числа примеров.

**Функция активации (activation function)**: функция, применяемая к выходу нейрона в нейронной сети. Она вводит нелинейность в модель, позволяя ей изучать сложные закономерности. Примеры: ReLU, сигмоида, тангенс.

**Алгоритм (Algorithm)**: набор инструкций, описывающих, как решить определённую задачу. В машинном обучении алгоритм — это конкретная процедура, которую модель использует для обучения на данных и прогнозирования.

**Искусственный Интеллект  (Artificial Intelligence)**: Более широкая концепция, чем машинное обучение. Относится к созданию компьютерных систем, способных выполнять задачи, которые обычно требуют человеческого интеллекта, такие как распознавание речи, решение проблем и обучение.

**Атрибут (Attribute):** характеристика или свойство объекта данных. Также называется признаком (feature).

##B

**Обратное распространение (Backpropagation):** алгоритм, используемый для обучения нейронных сетей. Он вычисляет градиент функции потерь по отношению к весам сети и использует этот градиент для обновления весов.

**Смещение (Bias):** Систематическая ошибка в данных или модели, которая приводит к необъективным результатам. 2) В нейронных сетях — настраиваемый параметр нейрона, позволяющий сдвинуть функцию активации.

**Компромисс между смещением и дисперсией (компромисс между сложностью модели и ее способностью обобщать на новые данные):** компромисс между сложностью модели (дисперсией) и ее способностью обобщать на новые данные (смещением). Более простые модели имеют высокое смещение и низкую дисперсию, а более сложные модели имеют низкое смещение и высокую дисперсию.

##C

**Классификация (Classification):** задача машинного обучения, в которой модель должна предсказать категорию или класс для каждого примера. Например, классификация изображений кошек и собак.

**Кластеризация (Clustering):** задача машинного обучения, в которой модель должна сгруппировать похожие примеры в кластеры.

**Матрица ошибок (Confusion Matrix):** таблица, показывающая производительность модели классификации. Она содержит информацию о количестве правильно и неправильно классифицированных примеров для каждого класса.

**Функция стоимости (Cost Function):** Смотрите Loss Function.

**Перекрёстная проверка (кросс-валидация):** метод оценки производительности модели на новых данных путём разделения данных на несколько частей (фолдов), обучения модели на нескольких фолдах и проверки на оставшемся фолде.

##D

**Аугментация данных (Data Augmentation):** техника увеличения размера обучающего набора данных путем создания новых примеров на основе существующих. Например, поворот, масштабирование или изменение яркости изображения.

**Интеллектуальный анализ данных (Data Mining):** область, смежная с машинным обучением, ориентированная на выявление закономерностей и знаний в больших наборах данных.

**Глубокое обучение (Deep Learning):** подмножество машинного обучения, которое использует нейронные сети с множеством слоёв (глубокие нейронные сети) для обучения на данных.

**Размерность (Dimension):** Количество атрибутов (признаков) в наборе данных.

**Выпадение (Dropout):** метод регуляризации в нейронных сетях, который случайным образом отключает некоторые нейроны во время обучения, чтобы предотвратить переобучение.

##E

**Эпоха (Epoch):** один полный проход обучающего набора данных через алгоритм машинного обучения.

**Оценка (Evaluation):** Процесс оценки производительности модели машинного обучения.

##F

**Признак (Feature):** характеристика или свойство объекта данных. Также называется атрибутом (attribute).

**Инженерия признаков (Feature Engineering):** процесс выбора, преобразования и создания новых признаков для повышения производительности модели машинного обучения.

**Выбор признаков (Feature Selection):** процесс выбора наиболее релевантных признаков для обучения модели машинного обучения.

**Нейронная сеть прямого распространения (Feedforward Neural Network):** тип нейронной сети, в которой информация движется только в одном направлении — от входа к выходу.

**F1-мера (F1-score):** гармоническое среднее точности и полноты. Используется для оценки качества модели классификации, особенно в случае несбалансированных классов.

**Складка (Фолд):** часть данных, используемая в кросс-валидации.
##G

**Градиентный спуск (Gradient Descent):** Итеративный алгоритм оптимизации, используемый для поиска минимума функции потерь. Он обновляет параметры модели в направлении, противоположном градиенту.

##H

**Гиперпараметр (Hyperparameter):** параметр, который устанавливается до начала обучения модели машинного обучения. Примеры: скорость обучения, количество слоёв в нейронной сети, количество деревьев в случайном лесу.

**Гипотеза (Hypothesis):** функция, которую модель машинного обучения использует для прогнозирования.


**Экземпляр (Instance):** отдельный объект данных. Также называется примером (example).

##K

**K-средних (K-Means):** алгоритм кластеризации, который группирует данные в K кластеров на основе расстояния до центроидов кластеров.

**K-ближайших соседей (KNN) (K-ближайших соседей):** алгоритм классификации и регрессии, который прогнозирует значение для нового примера на основе значений K ближайших к нему примеров в обучающем наборе данных.

##L

**Метка (Label):** категория или класс, присвоенный примеру в задаче классификации.

**Скорость обучения (Learning Rate):** гиперпараметр, определяющий размер шага, который делается при обновлении параметров модели во время обучения.

**Функция потерь (Loss Function):** функция, измеряющая разницу между прогнозами модели и фактическими значениями. Также называется функцией стоимости (cost function). Цель обучения — минимизировать функцию потерь.

##M

**Машинное обучение, МО (Machine Learning (ML)):** Область искусственного интеллекта, которая позволяет компьютерам учиться на данных без явного программирования.

**Модель (Model):** функция, которая преобразует входные данные в выходные. В машинном обучении модель обучается на данных, чтобы предсказывать новые данные.

##N

**Обработка естественного языка (NLP) (Natural Language Processing, NLP):** область искусственного интеллекта, которая занимается пониманием и обработкой человеческого языка.

**Нейронная сеть (Neural Network):** модель машинного обучения, вдохновлённая структурой и функциями человеческого мозга. Она состоит из взаимосвязанных нейронов, организованных в слои.

**Нормализация (Normalization):** приведение значений признаков к стандартному диапазону, например от 0 до 1.

##O

**Алгоритм оптимизации (Optimization Algorithm):** алгоритм, используемый для поиска наилучших параметров модели машинного обучения, которые минимизируют функцию потерь.

**Выброс (Outlier):** значение данных, значительно отличающееся от других значений в наборе данных.

##P

**Параметр (Parameter):** значение, которое модель машинного обучения изучает на основе данных во время обучения. Примеры: веса в нейронной сети, коэффициенты в линейной регрессии.

**Точность (в классификации) (Precision):** Мера того, насколько хорошо модель избегает ложных срабатываний. Рассчитывается как доля правильно классифицированных положительных примеров от общего числа примеров, классифицированных как положительные.

**Предварительно обученная модель (Pre-trained model):** модель, которая была обучена на большом наборе данных и может быть использована в качестве отправной точки для обучения на новом наборе данных.

##R

**Точность (полнота):** мера того, насколько хорошо модель избегает ложных пропусков. Рассчитывается как доля правильно классифицированных положительных примеров от общего числа фактических положительных примеров.

**Рекуррентная нейронная сеть (RNN) (Рекуррентная нейронная сеть, РНС):** тип нейронной сети, которая хорошо подходит для обработки последовательных данных, таких как текст и временные ряды.

**Регуляризация (сглаживание):** методы, используемые для предотвращения переобучения модели путём добавления штрафа за сложность модели к функции потерь.

**Регрессия (Regression):** задача машинного обучения, в которой модель должна предсказать числовое значение для каждого примера. Например, предсказание цены дома.

##S

**Обучение с учителем (Supervised Learning):** тип машинного обучения, при котором модель обучается на размеченных данных, то есть на данных, для которых известны правильные ответы (метки).

**Машина опорных векторов (Support Vector Machine (SVM)):** Алгоритм классификации, который находит оптимальную гиперплоскость для разделения данных на классы.

##T

**Обучающие данные (Training Data):** набор данных, используемый для обучения модели машинного обучения.

**Тестовые данные (Test Data):** набор данных, используемый для оценки производительности модели машинного обучения после обучения.

**Истинно положительный (TP) (True Positive):** пример, который был правильно классифицирован как положительный.

**Истинно отрицательный (True Negative (TN)):** Пример, который был правильно классифицирован как отрицательный.

##U

**Обучение без учителя (Unsupervised Learning):** тип машинного обучения, при котором модель обучается на неразмеченных данных, то есть на данных, для которых неизвестны правильные ответы (метки).

##V

**Проверочные данные (Validation Data):** набор данных, используемый для настройки гиперпараметров модели машинного обучения во время обучения.